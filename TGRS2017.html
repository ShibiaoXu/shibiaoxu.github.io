<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" slick-uniqueid="3">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="./Homepage_files/sty/jemdoc.css" type="text/css">
<style type="text/css">
</style>
<title>TGRS2017</title>
</head>


<body>
<div id="layout-content" style="margin-top:25px">

<!-- teaser -->
<table>
<tbody>
  <tr>    
    <td valign="top" align="center">     
      <b><font size="4" face="Times New Roman" >Automatic Road Detection and Centerline Extraction via Cascaded End-to-End Convolutional Neural Network</font></b>
      <br><br>
    </td>
  </tr>

  <tr>
    <td valign="top" align="center">
	 <font size="4" face="Times New Roman" > Guangliang Cheng</font> <font size="2"><sup>1, 2</sup></font> &emsp;&emsp;   
	 <font size="4" face="Times New Roman" > Ying Wang</font> <font size="2"><sup>1</sup></font> &emsp;&emsp;
	 <font size="4" face="Times New Roman" > <a href="https://shibiaoxu.github.io/"  target="_blank">Shibiao Xu (Corresponding author)</a> </font> <font size="2"><sup>1</sup></font> &emsp;&emsp;
	 <font size="4" face="Times New Roman" > Hongzhen Wang</font> <font size="2"><sup>1</sup></font> &emsp;&emsp;
	 	 <br>
	 <font size="4" face="Times New Roman" > <a href="http://www.escience.cn/people/smxiang/index.html"  target="_blank">Shiming Xiang</a> </font> <font size="2"><sup>1</sup></font> &emsp;&emsp;
	 <font size="4" face="Times New Roman" > <a href="http://people.ucas.ac.cn/~panchunhong"  target="_blank">Chunhong Pan</a> </font> <font size="2"><sup>1</sup></font> &emsp;&emsp;
	 <br> 
	 <font size="2"> <sup>1</sup></font> <font size="3" face="Times New Roman" ><a href="http://www.nlpr.ia.ac.cn/" target="_blank">National Laboratory of Pattern Recognition, </a><a href="http://english.ia.cas.cn/" target="_blank">Institute of Automation, Chinese Academy of Sciences</a></font> &emsp;&emsp;
	 <br> 
         <font size="2"> <sup>2</sup></font> <font size="3" face="Times New Roman" ><a href="http://english.ucas.ac.cn/" target="_blank">University of Chinese Academy of Sciences</a> </font>
	 &emsp;&emsp;
         <br>
	 <font size="3" face="Times New Roman" > IEEE Transactions on Geoscience and Remote Sensing (TGRS), 2017 </font>
         <br> <br>
    </td>
    </tr>

    <tr>
      <td valign="top" align="center">
         <img width="55%" src="./TGRS2017_files/network.png">
         <img width="43.5%" src="./TGRS2017_files/result.png">
      </td>
    </tr>

</tbody>
</table>

<!-- Abstract -->
<h2>Abstract</h2>


<table>
  <tbody>
  <tr>
    <p style="text-align:justify;">
    <font face="Times New Roman" >
     Accurate road detection and centerline extraction from very high resolution (VHR) remote sensing imagery are of central importance in a wide range of applications. Due to the complex backgrounds and occlusions of trees and cars, most road detection methods bring in the heterogeneous segments; besides for the centerline extraction task, most current approaches fail to extract a wonderful centerline network that appears smooth, complete, as well as single-pixel width. To address the abovementioned complex issues, we propose a novel deep model, i.e., a cascaded end-to-end convolutional neural network (CasNet), to simultaneously cope with the road detection and centerline extraction tasks. Specifically, CasNet consists of two networks. One aims at the road detection task, whose strong representation ability is well able to tackle the complex backgrounds and occlusions of trees and cars. The other is cascaded to the former one, making full use of the feature maps produced formerly, to obtain the good centerline extraction. Finally, a thinning algorithm is proposed to obtain smooth, complete, and single-pixel width road centerline network. Extensive experiments demonstrate that CasNet outperforms the state-of-the-art methods greatly in learning quality and learning speed. That is, CasNet exceeds the comparing methods by a large margin in quantitative performance, and it is nearly 25 times faster than the comparing methods. Moreover, as another contribution, a large and challenging road centerline data set for the VHR remote sensing image will be publicly available for further studies.
    </font>
    </p>
  </tr>

    <tr>
      <td align="center" width="25%">
        <img src="./TGRS2017_files/thumbmail.png" width="200">
      </td>
      <td>
          <strong>Paper</strong> [<a href="./TGRS2017_files/FINAL VERSION.pdf" target="_blank">PDF</a>] <br><br>
          <strong>DataSet </strong> [<a href="https://shibiaoxu.github.io">Coming Soon</a>] <br><br>
      </td>
    </tr>
  </tbody>
</table>

</div>
</body>
</html>
