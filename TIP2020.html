<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" slick-uniqueid="3">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="./Homepage_files/sty/jemdoc.css" type="text/css">
<style type="text/css">
</style>
<title>TIP2020</title>
</head>


<body>
<div id="layout-content" style="margin-top:25px">

<!-- teaser -->
<table>
<tbody>
  <tr>    
    <td valign="top" align="center">     
      <b><font size="4" face="Times New Roman" >Unsupervised Multi-view Constrained Convolutional Network for Accurate Depth Estimation</font></b>
      <br><br>
    </td>
  </tr>

  <tr>
    <td valign="top" align="center">
	 <font size="4" face="Times New Roman" > Yuyang Zhang</font> <font size="2"><sup>1</sup></font> &emsp;&emsp;         
<font size="4" face="Times New Roman" > <a href="https://shibiaoxu.github.io/"  target="_blank">Shibiao Xu</a> </font> <font size="2"><sup>1</sup></font> &emsp;&emsp;
	 <font size="4" face="Times New Roman" > <a href="https://dblp.org/pers/hd/w/Wu:Baoyuan"  target="_blank">Baoyuan Wu</a> </font> <font size="2"><sup>2</sup></font> &emsp;&emsp;
	<font size="4" face="Times New Roman" > Jian Shi</font> <font size="2"><sup>1</sup></font> &emsp;&emsp; 
	 <font size="4" face="Times New Roman" > <a href="http://www.escience.cn/people/mengweiliang/index.html"  target="_blank">Weiliang Meng</a> </font> <font size="2"><sup>1</sup></font> &emsp;&emsp;
	 <font size="4" face="Times New Roman" > <a href="http://people.ucas.ac.cn/~0005319?language=en"  target="_blank">Xiaopeng Zhang</a> </font> <font size="2"><sup>1</sup></font> &emsp;&emsp;
	 <br> 
	 <font size="2"> <sup>1</sup></font> <font size="3" face="Times New Roman" ><a href="http://www.nlpr.ia.ac.cn/" target="_blank">National Laboratory of Pattern Recognition, </a><a href="http://english.ia.cas.cn/" target="_blank">Institute of Automation, Chinese Academy of Sciences</a></font> &emsp;&emsp;
	 <br> 
         <font size="3"> <sup>2</sup></font> <font size="3" face="Times New Roman" ><a href="https://www.cuhk.edu.cn/en/" target="_blank">Chinese University of Hong Kong (Shenzhen)</a> </font>
	 &emsp;&emsp;
         <br>
	 <font size="3" face="Times New Roman" > IEEE Transactions on Image Processing (TIP), 2020 </font>
         <br> <br>
    </td>
    </tr>

    <tr>
      <td valign="top" align="center">
         <img width="62%" src="./TIP2020_files/overview.png">
         <img width="36%" src="./TIP2020_files/result.png">
      </td>
    </tr>

</tbody>
</table>

<!-- Abstract -->
<h2>Abstract</h2>


<table>
  <tbody>
  <tr>
    <p style="text-align:justify;">
    <font face="Times New Roman" >
     Accurate depth estimation from images is a fundamental problem in computer vision. In this paper, we propose an unsupervised learning based method to predict high-quality depth map from multiple images. A novel multi-view constrained DenseDepthNet is designed for this task. %multi-view constrained strategy of Our DenseDepthNet can effectively leverage both the low-level and high-level features of input images and generate appealing results, especially with sharp details. We employ the public datasets KITTI and Cityscapes for training in an end-to-end unsupervised fashion. A novel depth consistency loss based on multi-view geometry constraint is also applied to the corresponding points across pairwise images, which helps to improve the quality of predicted depth maps significantly. We conduct comprehensive evaluations on our DenseDepthNet and our depth consistency loss function. Experiments validate that our method outperforms the state-of-the-art unsupervised methods and produce comparable results with supervised methods.
    </font>
    </p>
  </tr>

    <tr>
      <td align="center" width="25%">
        <img src="./TIP2020_files/thumbmail.png" width="200">
      </td>
      <td>
          <strong>Paper</strong> [<a href="./TIP2020_files/FINAL VERSION.pdf" target="_blank">PDF</a>] <br><br>
          <strong>DenseDepthNet Code </strong> [<a href="https://pan.cstcloud.cn/s/Lw2uZgdRno">Code</a>] <br><br>
      </td>
    </tr>
  </tbody>
</table>

</div>
</body>
</html>
